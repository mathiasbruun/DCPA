{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "758966fb-f998-4d60-8820-760c9a6a727e",
   "metadata": {},
   "source": [
    "# First `politician2vec` demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083459f6-2d4e-474a-b797-f026abe57804",
   "metadata": {},
   "source": [
    "## To do\n",
    "- Descriptive statistics/viz for entire dataset\n",
    "- Settle on centroid calculation method (handle outliers better, remove alt method?)\n",
    "- Compile populism-related words for constructing axes\n",
    "- Determine possibilities of comparative analysis\n",
    "- Consistently change \"topic\" to \"party\"/\"cluster\" or the like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c05d8fdb-6e05-4234-a5d2-d78f07ec6cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: politician2vec 0.0.1\n",
      "Uninstalling politician2vec-0.0.1:\n",
      "  Successfully uninstalled politician2vec-0.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall politician2vec -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5fe62bc-30f3-4a7f-b2c5-82062cd7abdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+ssh://****@github.com/mathiasbruun/politician2vec.git\n",
      "  Cloning ssh://****@github.com/mathiasbruun/politician2vec.git to /private/var/folders/8q/02vc3fzn3r1fv7wzycyspjz80000gn/T/pip-req-build-fsg34oka\n",
      "  Running command git clone -q 'ssh://****@github.com/mathiasbruun/politician2vec.git' /private/var/folders/8q/02vc3fzn3r1fv7wzycyspjz80000gn/T/pip-req-build-fsg34oka\n",
      "Building wheels for collected packages: politician2vec\n",
      "  Building wheel for politician2vec (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for politician2vec: filename=politician2vec-0.0.1-py3-none-any.whl size=27418 sha256=58a4ae4ee4e1350bf9fb2793ad8a56ea6660655007757c07b8e1aad22e19f845\n",
      "  Stored in directory: /private/var/folders/8q/02vc3fzn3r1fv7wzycyspjz80000gn/T/pip-ephem-wheel-cache-hngzo8rd/wheels/ac/44/62/b0b3ddf2882cd1b1d1cc4e060c5c525b951ae01496d65cd472\n",
      "Successfully built politician2vec\n",
      "Installing collected packages: politician2vec\n",
      "Successfully installed politician2vec-0.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install git+ssh://git@github.com/mathiasbruun/politician2vec.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bad045e5-4959-4813-a433-383760381766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from politician2vec import Politician2Vec\n",
    "from politician2vec.utils import *\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "available_workers = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f04b4d9-247d-4bc1-b9ad-ad7ce97ef9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_path = 'data/clean/combined/subset_party_imputed_v2.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d80504e4-37cf-4c05-825f-6f5f4e9587af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(349594, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(test_data_path, 'rb') as p:\n",
    "    test_data = pickle.load(p)\n",
    "\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66235c0e-9843-4e4c-8b58-69d2f3c0b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parl_data = test_data.loc[\n",
    "#     (test_data['source'] == 'parliament') &\n",
    "#     ~(test_data['party'].isin(['SIU', 'NQ', 'JF', 'SP']))\n",
    "# ]\n",
    "#\n",
    "# tw_data = test_data.loc[\n",
    "#     test_data['source'] == 'twitter'\n",
    "# ]\n",
    "#\n",
    "meta_data = test_data.loc[\n",
    "    (test_data['source'] == 'meta') &\n",
    "    test_data['doc'].notna()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad98caa3-a8b4-4f6a-859f-9df0bf39655e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V      7307\n",
       "SF     4869\n",
       "S      3441\n",
       "LA     3424\n",
       "KF     2700\n",
       "DF     2087\n",
       "NB     1909\n",
       "RV     1593\n",
       "EL      823\n",
       "FG      675\n",
       "ALT     220\n",
       "DD       48\n",
       "M        28\n",
       "KD       14\n",
       "SIU       9\n",
       "UFG       5\n",
       "Name: party, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data['party'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "08f3e52e-b23a-4712-8526-9b4b6a346940",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_docs = meta_data.groupby(['full_name', 'party'])['doc'].apply('. '.join).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "faf6a41d-5de4-44c6-9a6d-cc65d8cb60f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs = [doc for doc in tw_data.doc]\n",
    "docs = [doc for doc in grouped_docs.doc]\n",
    "parties = np.array([party for party in grouped_docs.party])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f2c5f8d-f036-4995-a1d6-e28b031dd924",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_options = {\n",
    "    'min_count': 5,\n",
    "    'threshold': 1,\n",
    "    'delimiter': ' '\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f709bbde-4760-455d-87ea-cdcfe1e2ee90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 11:34:03,751 - politician2vec - INFO - Pre-processing documents for training\n",
      "2022-11-25 11:34:24,489 - politician2vec - INFO - Creating joint document/word embedding\n",
      "2022-11-25 11:37:33,078 - politician2vec - INFO - Estimating party positions using mean...\n",
      "2022-11-25 11:37:33,237 - politician2vec - INFO - All done!\n"
     ]
    }
   ],
   "source": [
    "pol2vec_model = Politician2Vec(\n",
    "    documents = docs,\n",
    "    custom_clusters = parties,\n",
    "    party_inference_method = 'mean',\n",
    "    tokenizer = preproc_docs,\n",
    "    embedding_model = 'doc2vec',\n",
    "    min_count = 50,\n",
    "    ngram_vocab = True,\n",
    "    ngram_vocab_args = ngram_options,\n",
    "    speed = 'fast-learn', # CHANGE FOR REAL RUNS\n",
    "    workers = available_workers\n",
    "    #doc2vec_vector_size = 300,\n",
    "    #doc2vec_window = 8,\n",
    "    #doc2vec_samples_threshold = 1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed72bac1-cd3b-48b6-8f50-dae9893bc8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: This should probably be implemented as a method of the Politician2Vec class\n",
    "def inspect_topic(politician2vec_model, topic_idx, n_docs=None, query_substr=None):\n",
    "    '''\n",
    "    Print top words and top docs for a given\n",
    "    topic.\n",
    "    -------\n",
    "    manual_num (int):  automatically assigned topic number (i.e. 0-indexed).\n",
    "    \n",
    "    n_docs (int, optional): n top documents to print for a given topic.\n",
    "        Default is to print all docs within a given topic.\n",
    "    \n",
    "    query_substr (str, optional): if specified, only documents containing\n",
    "        this substring will be printed. Cannot be specified with n_docs,\n",
    "        as this would return only results within a subset of topic docs.\n",
    "    '''\n",
    "\n",
    "    num_topics = politician2vec_model.get_num_topics()\n",
    "    topic_words, word_scores, topic_nums = politician2vec_model.get_topics(num_topics)\n",
    "\n",
    "    # Get topic sizes so we know max n docs\n",
    "    topic_sizes, topic_nums = politician2vec_model.get_topic_sizes()\n",
    "    docs_to_return = topic_sizes[topic_idx]\n",
    "\n",
    "    # Override n docs to return, if specified\n",
    "    if n_docs:\n",
    "        docs_to_return = n_docs\n",
    "\n",
    "    # Get docs for input topic id\n",
    "    documents, document_scores, document_ids = politician2vec_model.search_documents_by_topic(\n",
    "        topic_num=topic_idx,\n",
    "        num_docs=docs_to_return\n",
    "        )\n",
    "\n",
    "    # Limit output to docs containign certain substring, if specified\n",
    "    if query_substr and n_docs:\n",
    "        raise Exception('Please do NOT specify n_docs with substring query!\\nOtherwise the search is only carried out for a subset of topic docs.')\n",
    "    \n",
    "    # Throw exception if substring query attempted on subset of docs!\n",
    "    elif query_substr:\n",
    "        documents = [doc for doc in documents if query_substr in doc.lower()]\n",
    "\n",
    "    # Print output\n",
    "    print('--- TOP 50 WORDS ---\\n', topic_words[topic_idx], '\\n')\n",
    "\n",
    "    print(f'--- TOP {docs_to_return} DOCS. SUBSTRING QUERY: {query_substr} (n = {len(documents)}) ---\\n', documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1dd4df12-f6d3-4be7-b7dc-0a5767db72fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('seier', 0.5170028209686279),\n",
       " ('nye', 0.5106543302536011),\n",
       " ('christensen', 0.4494542181491852),\n",
       " ('borgerliges', 0.4007401466369629),\n",
       " ('🦢', 0.3813905417919159),\n",
       " ('peter', 0.3760186433792114),\n",
       " ('partier', 0.370720237493515),\n",
       " ('udlændinge', 0.351047158241272),\n",
       " ('asylstop', 0.3485393226146698),\n",
       " ('venstrefløjen', 0.3371717631816864),\n",
       " ('forklarer', 0.3317083716392517),\n",
       " ('større', 0.32527339458465576),\n",
       " ('udvises', 0.3219779133796692),\n",
       " ('politikerne', 0.3218039870262146),\n",
       " ('parti', 0.32109203934669495),\n",
       " ('islam', 0.3183261752128601),\n",
       " ('df', 0.31765878200531006),\n",
       " ('politikernes', 0.31552839279174805),\n",
       " ('netop', 0.3065086901187897),\n",
       " ('kriminelle', 0.30640098452568054),\n",
       " ('boje', 0.3052135109901428),\n",
       " ('jobcentrene', 0.30413007736206055),\n",
       " ('nedlægge', 0.3030591309070587),\n",
       " ('lande', 0.2970431447029114),\n",
       " ('rigsretssag', 0.29516732692718506)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors = pol2vec_model.model.wv\n",
    "word_vectors.most_similar(positive = ['borgerlige'], topn = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c63203b3-96b8-4b2d-b049-f0b6a608a344",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TOP 50 WORDS ---\n",
      " ['🌹 tak' '🌹 valgkampen' 'gerne 🌹' '🌹 så' '😊 🌹' 'folketinget 🌹' '🌹 velfærd'\n",
      " '️ 🌹' 'forskel 🌹' 'kampen 🌹' 'tech-skat sammen' 'virkelig gode'\n",
      " 'mere valgkampen' '🧓 🌹' 'hele valgkampen' '🌹 synes' 'socialdemokratiet 🌹'\n",
      " 'gerne gode' 'store teknologivirksomheder' '🌹 ❤' 'tak gode'\n",
      " 'godt hinanden' '🌹 🌹' '💚 🌹' 'godt gerne' 'velfærd 🌹' 'tider 🌹' 'først 🌹'\n",
      " 'sandra 🌹' '🌹 del' 'krydret god' 'valgkamp dag' 'godt se'\n",
      " 'resten valgkampen' 'hovedkontor sammen' '🌹 🇩' 'stor tak' 'utryg tid'\n",
      " 'god valgkamp' 'politik grøn' 'politikere bor' 'minde hinanden'\n",
      " 'tid store' '🌹 😊' 'tid opgaverne' 'andre gode' '🌹 socialdemokratiet'\n",
      " 'sammen kan' 'tak god' 'valgkampen 🙏'] \n",
      "\n",
      "--- TOP 1 DOCS. SUBSTRING QUERY: None (n = 1) ---\n",
      " ['Socialdemokratiet vil sætte velfærden først, indføre en ret til tidligere folkepension for de mest nedslidte og give en bæredygtig verden videre til vores børn. Det kan lade sig gøre. Men det kræver det en ny regering, der vil gøre gode tider bedre for alle.🌹 #LevStærktHeleLivet #Jan_vi_kan. Tak til min tidligere tillidsmandskollega på Lindøværftet Keld Westring for den fine anbefaling. Jeg er klar til at kæmpe videre på Christiansborg, hvis jeg får opbakningen og tilliden fra jer vælgere igen.🌹#Jan_vi_kan #LevStærktHeleLivet. Fordi alle har ret til en værdig tilbagetrækning fra arbejdsmarkedet. Ingen skal dø med arbejdstøjet på!🌹#LevStærktHeleLevet #Jan_vi_kan']\n"
     ]
    }
   ],
   "source": [
    "inspect_topic(pol2vec_model, 0, n_docs=1, query_substr=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a2c8507a-8782-4d52-a2b4-41fab473f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'embedding_models/politician2vec_test_meta_v1.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd159a62-0ece-47c6-8b77-6e3c32b2a46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pol2vec_model.save(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0622949d-fbea-486a-b7d8-37e4a2e165b4",
   "metadata": {},
   "source": [
    "### Viz dev below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "53ac4339-ab37-41ca-9aaf-77c0f93ea5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Politician2Vec model...\n",
      "Retrieving document embedding...\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "pol2vec_model, doc2vec_model = load_politician2vec_from_txt(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "33350c40-b001-424a-94ad-006ad9597c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have elected to extract only document vectors.\n",
      "Please note that further preprocessing -- such as filtering based on topics of\n",
      "interest -- may be desired in order to facilitate TensorBoard visualisation.\n",
      "Please see get_doc_topic_df(), vector_subset2tensor_without_words(), and\n",
      "metadata2tensor()\n",
      "\n",
      "Saving temp w2v file and converting to tensor. This may take a while...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-25 11:47:41,558 - word2vec2tensor - INFO - running /Users/mathiasbruun/me/anaconda3/lib/python3.7/site-packages/gensim/scripts/word2vec2tensor.py -i tensorboard_input/temp/doc_tensor_meta.w2v -o tensorboard_input/meta\n",
      "2022-11-25 11:47:41,559 - keyedvectors - INFO - loading projection weights from tensorboard_input/temp/doc_tensor_meta.w2v\n",
      "2022-11-25 11:47:41,601 - utils - INFO - KeyedVectors lifecycle event {'msg': 'loaded (194, 300) matrix of type float32 from tensorboard_input/temp/doc_tensor_meta.w2v', 'binary': False, 'encoding': 'utf8', 'datetime': '2022-11-25T11:47:41.590260', 'gensim': '4.1.2', 'python': '3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 05:57:50) \\n[Clang 11.1.0 ]', 'platform': 'Darwin-21.4.0-x86_64-i386-64bit', 'event': 'load_word2vec_format'}\n",
      "2022-11-25 11:47:41,643 - word2vec2tensor - INFO - 2D tensor file saved to tensorboard_input/meta_tensor.tsv\n",
      "2022-11-25 11:47:41,644 - word2vec2tensor - INFO - Tensor metadata file saved to tensorboard_input/meta_metadata.tsv\n",
      "2022-11-25 11:47:41,644 - word2vec2tensor - INFO - finished running word2vec2tensor.py\n"
     ]
    }
   ],
   "source": [
    "doc2vec2tensor(\n",
    "    doc2vec_model,\n",
    "    temp_w2v_path = 'tensorboard_input/temp/doc_tensor_meta.w2v',\n",
    "    tsv_prefix = 'tensorboard_input/meta',\n",
    "    output_docvecs = True,\n",
    "    output_wordvecs = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4e4c9095-3864-4dbc-95e2-ce5cebb325da",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words = len(doc2vec_model.wv)\n",
    "n_docs = len(doc2vec_model.dv)\n",
    "vocab = pol2vec_model.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "912b443b-38b9-4ea2-841e-a1d8a7d89e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TWITTER DEEPLEARN\n",
    "#topic_labels = {\n",
    "#    0: 'Venstre',\n",
    "#    1: 'Socialdemokratiet',\n",
    "#    2: 'Dansk_Folkeparti',\n",
    "#    3: 'Enhedslisten',\n",
    "#    4: 'Radikale_Venstre',\n",
    "#    5: 'SF',\n",
    "#    6: 'Konservative',\n",
    "#    7: 'Liberal_Alliance',\n",
    "#    8: 'Alternativet',\n",
    "#    9: 'Nye_Borgerlige',\n",
    "#    10: 'Frie_Grønne',\n",
    "#    11: 'Kristendemokraterne',\n",
    "#    12: 'Moderaterne'\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "2de68d38-25a3-4729-86f5-861f03c43e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PARLIAMENT FASTLEARN\n",
    "#topic_labels = {\n",
    "#    0: 'Socialdemokratiet',\n",
    "#    1: 'Venstre',\n",
    "#    2: 'Dansk_Folkeparti',\n",
    "#    3: 'Enhedslisten',\n",
    "#    4: 'Radikale Venstre',\n",
    "#    5: 'SF',\n",
    "#    6: 'Konservative',\n",
    "#    7: 'Liberal_Alliance',\n",
    "#    8: 'UFG',\n",
    "#    9: 'Alternativet',\n",
    "#    10: 'Danmarksdemokraterne',\n",
    "#    11: 'Nye Borgerlige',\n",
    "#    12: 'Frie Grønne',\n",
    "#    13: 'Moderaterne',\n",
    "#    14: 'Kristendemokraterne'\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "92db9ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# META FASTLEARN\n",
    "topic_labels = {\n",
    "   0: 'Socialdemokratiet',\n",
    "   1: 'Venstre',\n",
    "   2: 'Dansk_Folkeparti',\n",
    "   3: 'SF',\n",
    "   4: 'Radikale_Venstre',\n",
    "   5: 'Enhedslisten',\n",
    "   6: 'Konservative',\n",
    "   7: 'Liberal_Alliance',\n",
    "   8: 'Alternativet',\n",
    "   9: 'Nye_Borgerlige',\n",
    "   10: 'UFG',\n",
    "   11: 'Danmarksdemokraterne',\n",
    "   12: 'Grøndlandsk',\n",
    "   13: 'Frie_Grønne',\n",
    "   14: 'Kristendemokraterne',\n",
    "   15: 'Moderaterne'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d3bf42bf-c492-498b-bba4-63978cbddfe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic sizes before filtering (topic 16 is \"Other\"):\n",
      "\n",
      "[[ 0 42]\n",
      " [ 1 40]\n",
      " [ 2 23]\n",
      " [ 3 16]\n",
      " [ 4 14]\n",
      " [ 5 14]\n",
      " [ 6 13]\n",
      " [ 7 10]\n",
      " [ 8  8]\n",
      " [ 9  5]\n",
      " [10  3]\n",
      " [11  2]\n",
      " [12  1]\n",
      " [13  1]\n",
      " [14  1]\n",
      " [15  1]]\n"
     ]
    }
   ],
   "source": [
    "topic_df = get_doc_topic_df(\n",
    "    pol2vec_model,\n",
    "    no_substantive_topics = 16,\n",
    "    snippets = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "468b7780-471e-4b88-8352-d5166a4fbe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Okay, we have clearly made a mistake. By swapping party classes for politicians,\n",
    "# we are now telling the model to find politician-level centroids wrt. politician superdocs, yielding...\n",
    "# ... well, obviously, 154 centroids, correspodning to the 154 super documents. That makes no sense,\n",
    "# since the centroid and the superdocument will be the same by construction.\n",
    "#\n",
    "# We either want document-level centroids clustered by politician OR politician-level centroids clustered\n",
    "# by party. So politician superdocs + input party label array.\n",
    "#\n",
    "# TODO: Also extract topic vectors themselves, which we usually never do!\n",
    "#\n",
    "# TODO: Calculate medioid instead of centroid? To account for noisy estimates of politician positions?\n",
    "#\n",
    "# TODO: Perhaps chunk the politician-level superdocuments according to a certain special character used\n",
    "# to join them? Could increase performance in doc2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "776ec21f-795a-4261-8a40-3dc874df2960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_name</th>\n",
       "      <th>party</th>\n",
       "      <th>doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aki-Matilda Høegh-Dam</td>\n",
       "      <td>SIU</td>\n",
       "      <td>✨Sapiillutit inuiaqatigiinni peqataasarit.✨\\n\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alex Vanopslagh</td>\n",
       "      <td>LA</td>\n",
       "      <td>Røde Alex har kun hånlig latter til overs for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alternativet</td>\n",
       "      <td>ALT</td>\n",
       "      <td>Til tonerne af jazz og smagen af lækker cider ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anders Kronborg</td>\n",
       "      <td>S</td>\n",
       "      <td>Udvikling til hjemstavnen. Vestjylland skal ig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andreas Steenberg</td>\n",
       "      <td>RV</td>\n",
       "      <td>Hvor dum og uretfærdig kan vores udlændingelov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               full_name party  \\\n",
       "0  Aki-Matilda Høegh-Dam   SIU   \n",
       "1        Alex Vanopslagh    LA   \n",
       "2           Alternativet   ALT   \n",
       "3        Anders Kronborg     S   \n",
       "4      Andreas Steenberg    RV   \n",
       "\n",
       "                                                 doc  \n",
       "0  ✨Sapiillutit inuiaqatigiinni peqataasarit.✨\\n\\...  \n",
       "1  Røde Alex har kun hånlig latter til overs for ...  \n",
       "2  Til tonerne af jazz og smagen af lækker cider ...  \n",
       "3  Udvikling til hjemstavnen. Vestjylland skal ig...  \n",
       "4  Hvor dum og uretfærdig kan vores udlændingelov...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_docs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4d29f0e1-e1f6-422c-b039-74197be8f213",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df['snippet'] = grouped_docs['full_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2a3d0664-6138-4cd9-828c-31020574e52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>top</th>\n",
       "      <th>snippet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>Aki-Matilda Høegh-Dam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>Alex Vanopslagh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>Alternativet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Anders Kronborg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Andreas Steenberg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>189</td>\n",
       "      <td>1</td>\n",
       "      <td>Ulla Tørnæs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>Venstre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>191</td>\n",
       "      <td>7</td>\n",
       "      <td>Villum Christensen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>Yildiz Akdogan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>193</td>\n",
       "      <td>4</td>\n",
       "      <td>Zenia Stampe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>194 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc  top                snippet\n",
       "0      0   12  Aki-Matilda Høegh-Dam\n",
       "1      1    7        Alex Vanopslagh\n",
       "2      2    8           Alternativet\n",
       "3      3    0        Anders Kronborg\n",
       "4      4    4      Andreas Steenberg\n",
       "..   ...  ...                    ...\n",
       "189  189    1            Ulla Tørnæs\n",
       "190  190    1                Venstre\n",
       "191  191    7     Villum Christensen\n",
       "192  192    0         Yildiz Akdogan\n",
       "193  193    4           Zenia Stampe\n",
       "\n",
       "[194 rows x 3 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e8618fb2-2003-4a03-bfea-63fe7ec4b095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pol2vec_model.topic_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "038ccf66-adde-4837-8003-ae4c0ec7025c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata2tensor(\n",
    "    topic_df,\n",
    "    metadata_path = 'tensorboard_input/meta_metadata.tsv',\n",
    "    label_list = topic_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3c3131d9-5ec2-44c2-be8c-f6b4fd4265d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test read of tensor output\n",
    "with open('tensorboard_input/meta_tensor.tsv','r') as r:\n",
    "    lines_test = r.readlines()\n",
    "\n",
    "len(lines_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "59ef2289-af9d-478d-909d-fa71c6b0390a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def partyvecs2tensor(party_vecs, out_path):\n",
    "    vec_strs = []\n",
    "\n",
    "    for vec in party_vecs:\n",
    "        vec_str = ''.join([str(val) +'\\t' for val in vec]).rstrip('\\t')\n",
    "        vec_strs.append(vec_str)\n",
    "\n",
    "    tensor_str = '\\n'.join(vec_strs)\n",
    "    \n",
    "    with open(out_path, 'w') as f:\n",
    "        f.write(tensor_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "48ed2518-84bd-4d85-883d-9d0ae2963240",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_tensors(tensor_files, out_path):\n",
    "    tensor_strs = []\n",
    "    \n",
    "    for file in tensor_files:\n",
    "        tensor_str = pd.read_csv(file, sep = '\\t', header = None)\n",
    "        tensor_strs.append(tensor_str)\n",
    "    \n",
    "    concat_tensor = pd.concat(tensor_strs)\n",
    "    \n",
    "    concat_tensor.to_csv(out_path, sep = '\\t', header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "126ed041-77fb-46dd-a9c0-41b7e218b6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "partyvecs2tensor(\n",
    "    party_vecs = pol2vec_model.topic_vectors,\n",
    "    out_path = 'tensorboard_input/meta_parties.tsv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "3fb10a62-334d-4cef-8312-6c058a229622",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.DataFrame(topic_labels, index = ['doc']).T\n",
    "#label_df['topic'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b4316d49-0162-4bf5-b7c0-c47d781bd912",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df.to_csv(\n",
    "    'tensorboard_input/meta_parties_metadata.tsv',\n",
    "    sep = '\\t',\n",
    "    header = False,\n",
    "    index = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "34c8a19e-9c87-4644-a84f-cae422b456c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine docvecs and partyvecs\n",
    "politician_file = 'tensorboard_input/meta_tensor.tsv'\n",
    "party_file = 'tensorboard_input/meta_parties.tsv'\n",
    "\n",
    "tensor_files = [politician_file, party_file]\n",
    "concat_tensors(tensor_files, 'tensorboard_input/meta_combined.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bb79895f-e50c-4886-9b7b-a8ae5ad9119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine metadata\n",
    "politician_file = 'tensorboard_input/meta_metadata.tsv'\n",
    "party_file = 'tensorboard_input/meta_parties_metadata.tsv'\n",
    "\n",
    "tensor_files = [politician_file, party_file]\n",
    "concat_tensors(tensor_files, 'tensorboard_input/meta_combined_metadata.tsv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "df4b203bae24b8e546cac67fa1e5ed4e3ec7bcadeabf2e990fec7c51e0eb834e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
